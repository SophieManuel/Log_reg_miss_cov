---
title: "Simu_1cov"
author: "Sophie Manuel"
date: "27/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(misaem)
library(MASS)
library(mvtnorm)
library(mice)
library(ggplot2)
library(RColorBrewer)
library(tidyr)
theme_set(theme_bw())
```

# 1covariable & 10% manquants

initialisation du jeu de données avec 1 covariable et 10% de valeur manquante
```{r}
#n <- 10000  # number of subjects
n <- 500 # or a smaller number of subjects 
p <- 1     # number of explanatory variables
mu.star <- 1:p  # mean of the explanatory variables
sd <- 1:p # standard deviations

Sigma.star <- sd^2 # variance-covariance matrix of the explanatory variables
beta.star <- 0.5 # coefficients of logistic regression
beta0.star <- -0.2  # intercept
beta.true = c(beta0.star,beta.star)
#percentage of missingness
p.miss <- 0.10 
patterns = runif(n*p)<p.miss
```

## MCAR

algo pour MCAR et 10% d'erreur
```{r}
nbsim = 1
EST.saem = EST.comp = EST.cc = matrix(0, 2*nbsim,length(beta.star)+2)
STD.saem = STD.comp = STD.cc = matrix(0, nbsim,length(beta.star)+1)
LENGTH.saem = LENGTH.comp = LENGTH.cc = matrix(0, nbsim,length(beta.star)+1)
count.saem = count.comp = count.cc  = rep(0,p+1)

for (NB in 1:nbsim){
  set.seed(NB)
  # complete data simulation
  X.complete <- matrix(rnorm(n*p), nrow=n)%*%chol(Sigma.star) + matrix(rep(mu.star,n), nrow=n, byrow = TRUE)
  p1 <- 1/(1+exp(-X.complete%*%beta.star-beta0.star))
  y <- as.numeric(runif(n)<p1)
  
  # ----- No NA : classical estimation in the case without missingness
  data.complete <- data.frame(y=y,X.complete)
  model.complete <- glm(y ~.,family=binomial(link='logit'),data=data.complete)
  beta0.complete <- model.complete$coefficients[1]
  beta.complete <- model.complete$coefficients[2:(p+1)]
  P <- predict(model.complete, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.complete)
  V_complete <- solve(t(X)%*%W%*%X)
  std.complete <- sqrt(diag(V_complete))
  
  # generating missing data - MCAR missingness
  X.obs <- X.complete
  patterns = runif(n*p)<p.miss
  X.obs[patterns] <- NA
  X.obs<-data.frame(X.obs)
  
  # ------- CC : estimation ignoring the missing data
  data.obs <- data.frame(y=y,X.obs)
  model.obs <- glm(y ~.,family=binomial(link='logit'),data=data.obs)
  beta0.cc <- model.obs$coefficients[1]
  beta.cc <- model.obs$coefficients[2:(p+1)]
  P <- predict(model.obs, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.obs)
  V_cc <- solve(t(X)%*%W%*%X)
  std.cc <- sqrt(diag(V_cc))
  
 # -------  SAEM
  list.saem=miss.glm(y~.,data=X.obs, print_iter=FALSE,var_cal=TRUE)
  beta.saem = list.saem$coefficients
  std.saem = list.saem$s.err
  
  EST.comp[NB,] = c(beta0.complete,beta.complete, "MCAR")
  EST.cc[NB,] = c(beta0.cc,beta.cc, "MCAR")
  EST.saem[NB,] = c(beta.saem, "MCAR")

  STD.comp[NB,] = std.complete
  STD.cc[NB,] = std.cc
  STD.saem[NB,] = std.saem


  ci.comp_ceil =  c(beta0.complete,beta.complete) + 1.96*std.complete
  ci.comp_ground =  c(beta0.complete,beta.complete) - 1.96*std.complete
  ci.cc_ceil =  c(beta0.cc,beta.cc) + 1.96*std.cc
  ci.cc_ground =  c(beta0.cc,beta.cc) - 1.96*std.cc
  ci.saem_ceil = beta.saem + 1.96*std.saem
  ci.saem_ground = beta.saem - 1.96*std.saem

  LENGTH.comp[NB,] = ci.comp_ceil - ci.comp_ground
  LENGTH.cc[NB,] = ci.cc_ceil - ci.cc_ground
  LENGTH.saem[NB,] = ci.saem_ceil - ci.saem_ground
  for(i in 1:(p+1)){
    if( ci.comp_ground[i] <=beta.true[i] & ci.comp_ceil[i]>beta.true[i]){
      count.comp[i]<-count.comp[i]+1
    }
    if( ci.cc_ground[i] <=beta.true[i] & ci.cc_ceil[i]>beta.true[i]){
      count.cc[i]<-count.cc[i]+1
    }
    if( ci.saem_ground[i] <=beta.true[i] & ci.saem_ceil[i]>beta.true[i]){
      count.saem[i]<-count.saem[i]+1
    }
  }
}
```


```{r}
#length
#ci
#count
sum(count.comp)/6000
sum(count.cc)/6000
sum(count.saem)/6000

sum(LENGTH.comp[,1])/1000
sum(LENGTH.comp[,2])/1000

mean(LENGTH.cc)
mean(LENGTH.comp)
mean(LENGTH.saem)
```

## MAR

Estimation des poids de la combinaison linéaire non-unique par la méthode de MC en tatonnant.
```{r}
simMC <- 1000
vect <- NULL
gam0 <- 100
for (nMC in 1:simMC)
{
  X.complete <- matrix(rnorm(n*p), nrow=n)%*%chol(Sigma.star) + matrix(rep(mu.star,n), nrow=n, byrow = TRUE)
  p1 <- 1/(1+exp(-X.complete%*%beta.star-beta0.star))
  y <- as.numeric(runif(n)<p1)
  
  # generating missing data - MAR missingness
   X.obs <- X.complete
   for(i in 1){
     z <- y%*%matrix(gam0,ncol=1) # linear combination 
     pr <- 1/(1+exp(-z))         # pass through an inv-logit function
     r <- rbinom(n,1,pr)      # bernoulli response variable
     X.obs[r==0,i]<-NA
   }
   vect[nMC]<- mean(is.na(X.obs[,1]))
} 

E_MC <- mean(vect)
sd_MC <- sd(vect)
IC_U <- E_MC + 1.96 * sd_MC/sqrt(simMC)
IC_L <- E_MC - 1.96 * sd_MC/sqrt(simMC)

cat('percentage of NA for MC : ', E_MC, 'with confidence interval 95 % of : [',IC_L, ', ', IC_U ,'] with gamma_0 = ', gam0,'\n')
```


algo pour MCAR et 10% d'erreur
```{r}
nbsim = 1
STD.saem = STD.comp = STD.cc = matrix(0, nbsim,length(beta.star)+1)
LENGTH.saem = LENGTH.comp = LENGTH.cc = matrix(0, nbsim,length(beta.star)+1)
count.saem = count.comp = count.cc  = rep(0,p+1)

for (NB in 1:nbsim){
  set.seed(NB)
  # complete data simulation
  X.complete <- matrix(rnorm(n*p), nrow=n)%*%chol(Sigma.star) + matrix(rep(mu.star,n), nrow=n, byrow = TRUE)
  p1 <- 1/(1+exp(-X.complete%*%beta.star-beta0.star))
  y <- as.numeric(runif(n)<p1)
  
  # ----- No NA : classical estimation in the case without missingness
  data.complete <- data.frame(y=y,X.complete)
  model.complete <- glm(y ~.,family=binomial(link='logit'),data=data.complete)
  beta0.complete <- model.complete$coefficients[1]
  beta.complete <- model.complete$coefficients[2:(p+1)]
  P <- predict(model.complete, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.complete)
  V_complete <- solve(t(X)%*%W%*%X)
  std.complete <- sqrt(diag(V_complete))
  
#  # generating missing data - MAR missingness
#  X.obs <- X.complete
#  for(i in c(2,4,5)){
#   z <- cbind(y,X.complete[,c(1,3)])%*%matrix(sample(-5:5, 3, replace=T),ncol=1) # linear combination #(coefficients choosen with Monte Carlo estimation)
#   pr <- 1/(1+exp(-z))         # pass through an inv-logit function
#   r <- rbinom(n,1,pr)      # bernoulli response variable
#   X.obs[r==0,i]<-NA
#  }
  
  # ------- CC : estimation ignoring the missing data
  data.obs <- data.frame(y=y,X.obs)
  model.obs <- glm(y ~.,family=binomial(link='logit'),data=data.obs)
  beta0.cc <- model.obs$coefficients[1]
  beta.cc <- model.obs$coefficients[2:(p+1)]
  P <- predict(model.obs, type = "response")
  W <- diag(P*(1-P))
  X <- model.matrix(model.obs)
  V_cc <- solve(t(X)%*%W%*%X)
  std.cc <- sqrt(diag(V_cc))
  
 # -------  SAEM
  list.saem=miss.glm(y~.,data=X.obs, print_iter=FALSE,var_cal=TRUE)
  beta.saem = list.saem$coefficients
  std.saem = list.saem$s.err
  
  EST.comp[NB,] = c(beta0.complete,beta.complete, "MAR")
  EST.cc[NB,] = c(beta0.cc,beta.cc, "MAR")
  EST.saem[NB,] = c(beta.saem, "MAR")

  STD.comp[NB,] = std.complete
  STD.cc[NB,] = std.cc
  STD.saem[NB,] = std.saem


  ci.comp_ceil =  c(beta0.complete,beta.complete) + 1.96*std.complete
  ci.comp_ground =  c(beta0.complete,beta.complete) - 1.96*std.complete
  ci.cc_ceil =  c(beta0.cc,beta.cc) + 1.96*std.cc
  ci.cc_ground =  c(beta0.cc,beta.cc) - 1.96*std.cc
  ci.saem_ceil = beta.saem + 1.96*std.saem
  ci.saem_ground = beta.saem - 1.96*std.saem

  LENGTH.comp[NB,] = ci.comp_ceil - ci.comp_ground
  LENGTH.cc[NB,] = ci.cc_ceil - ci.cc_ground
  LENGTH.saem[NB,] = ci.saem_ceil - ci.saem_ground
  for(i in 1:(p+1)){
    if( ci.comp_ground[i] <=beta.true[i] & ci.comp_ceil[i]>beta.true[i]){
      count.comp[i]<-count.comp[i]+1
    }
    if( ci.cc_ground[i] <=beta.true[i] & ci.cc_ceil[i]>beta.true[i]){
      count.cc[i]<-count.cc[i]+1
    }
    if( ci.saem_ground[i] <=beta.true[i] & ci.saem_ceil[i]>beta.true[i]){
      count.saem[i]<-count.saem[i]+1
    }
  }
}
```


```{r}
#length
#ci
#count
sum(count.comp)/6000
sum(count.cc)/6000
sum(count.saem)/6000

sum(LENGTH.comp[,1])/1000
sum(LENGTH.comp[,2])/1000

mean(LENGTH.cc)
mean(LENGTH.comp)
mean(LENGTH.saem)
```

```{r}
dfbeta1 <- data.frame("Estimateur"= rbind(EST.comp[,2], EST.cc[,2], EST.saem[,2]), "meth" = as.factor( c(rep("comp",nbsim), rep("cc",nbsim), rep("saem",nbsim))), "alea"= as.factor(rep(EST.comp[,3],3))) # dernière colonne du tableau pour créer l'indicatrice MCAR/MAR
```

boxplots esthétiques comparaison MCAR/MAR pour comp, cc et saem, 10% valeurs manquantes n=500
```{r}
#dfbeta1 <- data.frame("comp"=EST.comp[,2],"cc"=EST.cc[,2],"saem"=EST.saem[,2], alea= as.factor(EST.comp[,3])) # dernière colonne du tableau pour créer l'indicatice MCAR/MAR
box <- ggplot(dfbeta1, aes(meth, Estimateur)) + geom_boxplot(aes(fill=alea))
box <- box + ggtitle("Boxplots de la répartion des données en fonction \ndu type d'aléatoire et des méthodes d'estimation")
box + theme(plot.title = element_text(hjust = 0.5))
```


boxplots simples
```{r, echo=F}
boxplot(EST.comp[,2],EST.cc[,2],EST.saem[,2],names=c("comp","cc","saem"),xlab="m?thode"); title("distribx1 mcar");abline(h=0.5)
boxplot(EST.comp[,3],EST.cc[,3],EST.saem[,3],names=c("comp","cc","saem"),xlab="m?thode"); title("distribx2 mcar");abline(h=-0.3)
boxplot(EST.comp[,4],EST.cc[,4],EST.saem[,4],names=c("comp","cc","saem"),xlab="m?thode"); title("distribx3 mcar");abline(h=1)

```

